{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13601148,"sourceType":"datasetVersion","datasetId":8642778},{"sourceId":13614634,"sourceType":"datasetVersion","datasetId":8652323}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Predicción de Diabetes\n## Hackathon HackUPM 2025 \n\n**Pipeline completo:**\n1. Cargar train.json + test.json\n2. Extraer edad, género, features clínicos (con regex robustas y negaciones)\n3. Generar embeddings con BioClinicalBERT (768-dim)\n4. Agrupar por paciente (media de features + embeddings)\n5. EDA completo sin errores\n6. Modelado con RandomForest\n7. Predicciones finales en test\n8. Guardado en múltiples formatos\n\n**Autores:**\n**Fecha:** 03-11-2025\n","metadata":{}},{"cell_type":"code","source":"# INSTALACIONES (ejecutar si es primera vez, descomentar)\n!pip install -q transformers torch pandas numpy tqdm scikit-learn\n!pip install --upgrade git+https://github.com/huggingface/transformers.git\n!pip install word2number\n\nfrom word2number import w2n\nimport json\nimport pandas as pd\nimport numpy as np\nimport torch\nimport re\nimport warnings\nfrom transformers import AutoTokenizer, AutoModel\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n\nwarnings.filterwarnings('ignore')\n\nprint(\"Librerías importadas\")\nprint(f\"CUDA disponible: {torch.cuda.is_available()}\") # CUDA es una plataforma de computación de Nvidia que ejecuta opers en las GPUs.\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # prepara tu código para trabajar en la GPU si está disponible, o en la CPU si no lo está.\nprint(f\"Dispositivo: {device}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T18:38:45.393523Z","iopub.execute_input":"2025-11-04T18:38:45.394228Z","iopub.status.idle":"2025-11-04T18:41:14.340374Z","shell.execute_reply.started":"2025-11-04T18:38:45.394194Z","shell.execute_reply":"2025-11-04T18:41:14.339504Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mCollecting git+https://github.com/huggingface/transformers.git\n  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-o2c7oknx\n  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-o2c7oknx\n  Resolved https://github.com/huggingface/transformers.git to commit 020e713ac8e70bd2e72bcd12dc6bd1ada6162562\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==5.0.0.dev0) (3.19.1)\nCollecting huggingface-hub==1.0.0.rc6 (from transformers==5.0.0.dev0)\n  Downloading huggingface_hub-1.0.0rc6-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==5.0.0.dev0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==5.0.0.dev0) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==5.0.0.dev0) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==5.0.0.dev0) (2025.9.18)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==5.0.0.dev0) (2.32.5)\nCollecting tokenizers<=0.23.0,>=0.22.0 (from transformers==5.0.0.dev0)\n  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\nRequirement already satisfied: typer-slim in /usr/local/lib/python3.11/dist-packages (from transformers==5.0.0.dev0) (0.19.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers==5.0.0.dev0) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==5.0.0.dev0) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==1.0.0.rc6->transformers==5.0.0.dev0) (2025.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==1.0.0.rc6->transformers==5.0.0.dev0) (0.28.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==1.0.0.rc6->transformers==5.0.0.dev0) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==1.0.0.rc6->transformers==5.0.0.dev0) (1.1.10)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==5.0.0.dev0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==5.0.0.dev0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==5.0.0.dev0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==5.0.0.dev0) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==5.0.0.dev0) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==5.0.0.dev0) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==5.0.0.dev0) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==5.0.0.dev0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==5.0.0.dev0) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==5.0.0.dev0) (2025.8.3)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer-slim->transformers==5.0.0.dev0) (8.3.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->huggingface-hub==1.0.0.rc6->transformers==5.0.0.dev0) (4.11.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->huggingface-hub==1.0.0.rc6->transformers==5.0.0.dev0) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub==1.0.0.rc6->transformers==5.0.0.dev0) (0.16.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==5.0.0.dev0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==5.0.0.dev0) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers==5.0.0.dev0) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers==5.0.0.dev0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers==5.0.0.dev0) (2024.2.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->huggingface-hub==1.0.0.rc6->transformers==5.0.0.dev0) (1.3.1)\nDownloading huggingface_hub-1.0.0rc6-py3-none-any.whl (502 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.0/502.0 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: transformers\n  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for transformers: filename=transformers-5.0.0.dev0-py3-none-any.whl size=11358702 sha256=1a9f8f8241b077b2c027deb17f60959bb57a199314c2f9ce14dd066585309822\n  Stored in directory: /tmp/pip-ephem-wheel-cache-hhqs6yef/wheels/32/4b/78/f195c684dd3a9ed21f3b39fe8f85b48df7918581b6437be143\nSuccessfully built transformers\nInstalling collected packages: huggingface-hub, tokenizers, transformers\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 0.36.0\n    Uninstalling huggingface-hub-0.36.0:\n      Successfully uninstalled huggingface-hub-0.36.0\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.21.2\n    Uninstalling tokenizers-0.21.2:\n      Successfully uninstalled tokenizers-0.21.2\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.53.3\n    Uninstalling transformers-4.53.3:\n      Successfully uninstalled transformers-4.53.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\nsentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 5.0.0.dev0 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed huggingface-hub-1.0.0rc6 tokenizers-0.22.1 transformers-5.0.0.dev0\nCollecting word2number\n  Downloading word2number-1.1.zip (9.7 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nBuilding wheels for collected packages: word2number\n  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5568 sha256=a90738d90334bcb1cae991a38c4c10e54e713f7e4ca08aa0de31343ff14886d3\n  Stored in directory: /root/.cache/pip/wheels/cd/ef/ae/073b491b14d25e2efafcffca9e16b2ee6d114ec5c643ba4f06\nSuccessfully built word2number\nInstalling collected packages: word2number\nSuccessfully installed word2number-1.1\nLibrerías importadas\nCUDA disponible: True\nDispositivo: cuda\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## 1️⃣ Cargar Datos (train.json + test.json)","metadata":{}},{"cell_type":"code","source":"print(\"\\nLeyendo train.json...\")\nwith open(\"/kaggle/input/data1222/train.json\", \"r\") as f:\n    train_data = json.load(f)\n\nprint(\"Leyendo test.json...\")\nwith open(\"/kaggle/input/data1222/test.json\", \"r\") as f:\n    test_data = json.load(f)\n\n# Crear DataFrames iniciales\ndf_train_raw = pd.DataFrame(train_data)\ndf_test_raw = pd.DataFrame(test_data)\n\nprint(f\"\\n Train: {len(df_train_raw)} registros, {df_train_raw.shape[1]} columnas\")\nprint(f\" Test: {len(df_test_raw)} registros, {df_test_raw.shape[1]} columnas\")\n\nprint(f\"\\n Columnas : {df_train_raw.columns.tolist()}\")\n\nprint(f\"\\n Distribución diabetes en TRAIN:\")\nprint(df_train_raw[\"has_diabetes\"].value_counts())\nprint(f\"Proporción positivos: {df_train_raw['has_diabetes'].mean()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T18:42:01.297204Z","iopub.execute_input":"2025-11-04T18:42:01.297972Z","iopub.status.idle":"2025-11-04T18:42:01.396201Z","shell.execute_reply.started":"2025-11-04T18:42:01.297948Z","shell.execute_reply":"2025-11-04T18:42:01.395366Z"}},"outputs":[{"name":"stdout","text":"\nLeyendo train.json...\nLeyendo test.json...\n\n Train: 3000 registros, 3 columnas\n Test: 300 registros, 2 columnas\n\n Columnas : ['patient_id', 'has_diabetes', 'medical_note']\n\n Distribución diabetes en TRAIN:\nhas_diabetes\n0    2100\n1     900\nName: count, dtype: int64\nProporción positivos: 0.3\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## 2️⃣ Extraccion de features clinicos","metadata":{}},{"cell_type":"code","source":"outliers = {\n    \"age\": [],\n    \"glucose\": [],\n    \"hba1c\": [],\n    \"bmi\": []\n}\n\ndef safe_float(x):\n    \"\"\"Convierte a float de forma segura.\"\"\"\n    try:\n        return float(x)\n    except:\n        return np.nan\n\ndef extract_age(text):\n    \"\"\"Extrae edad con rango válido 0-120.\"\"\"\n    if not isinstance(text, str):\n        return np.nan\n    t = text.lower()\n    # Patrón 1: \"X-year-old\" o \"age X\"\n    m = re.search(r'(\\d{1,3})\\s*(?:year)?-?\\s*(?:year-old|yr|years?\\s*old)', t)\n    age = None\n    if not m:\n        m = re.search(r'(?:age|aged)\\s*(?:is)?\\s*(\\d{1,3})\\b', t)\n        if not m:\n            m = re.search(r\"\\b([a-zA-Z]+(?:[-\\s][a-zA-Z]+)*)-year-old\\b\", t)\n            if m:\n                age = w2n.word_to_num(m.group(1))\n    if not age:\n        age = int(m.group(1)) if m else np.nan\n    if not m:\n        outliers[\"age\"].append(t)\n    return age if (not np.isnan(age) and 0 <= age <= 120) else np.nan\n\ndef extract_gender(text):\n    \"\"\"Extrae género (male/female/unknown).\"\"\"\n    if not isinstance(text, str):\n        return \"unknown\"\n    t = text.lower()\n    male_count = len(re.findall(r'\\b(?:male|man|he|his|him|boy)\\b', t))\n    female_count = len(re.findall(r'\\b(?:female|woman|she|her|girl)\\b', t))\n\n    if male_count > 0 and female_count == 0:\n        return \"male\"\n    elif female_count > 0 and male_count == 0:\n        return \"female\"\n    elif male_count == female_count == 0:\n        return \"unknown\"\n    else:\n        return \"male\" if male_count >= female_count else \"female\"\n\ndef extract_bmi(text):\n    \"\"\"Extrae BMI con rango válido 8-80.\"\"\"\n    if not isinstance(text, str):\n        return np.nan\n    t = text.lower()\n    m = re.search(r'\\b(?:bmi|imc)\\b[^0-9]{0,30}(\\d{1,3}(?:\\.\\d+)?)', t)\n    if not m:\n        m = re.search(r'\\b(?:bmi|imc)\\b.{0,26}range.{0,10}(\\d{1,3}(?:[.,]\\d+)?)', t)\n    v = safe_float(m.group(1)) if m else np.nan\n    if not m:\n        outliers[\"bmi\"].append(t)\n    return v if (not np.isnan(v) and 0 <= v <= 80) else np.nan\n\ndef extract_hba1c(text):\n    \"\"\"Extrae HbA1c con rango válido 3-20.\"\"\"\n    if not isinstance(text, str):\n        return np.nan\n    t = text.lower()\n    # Ventana local: hasta 20 chars después de \"hba1c\"\n    m = re.search(r'(?:hba1c|a1c)[^0-9]{0,20}(\\d{1,2}(?:\\.\\d+)?)\\s*%?', t)\n    if not m:\n        pattern = re.compile(\n            r'\\b(?:hba1c(?: level)?s?\\b.{0,10}(?:is|are|was|were|within|of)?\\s*(very\\s+high|high|elevated|normal|within normal limits|low)|(very\\s+high|high|elevated|normal|within normal limits|low)\\s+(?:levels\\s+of\\s+)?hba1c)\\b',\n            re.IGNORECASE\n        )\n        m = pattern.search(t)\n        if m:\n            mapping = {\n                \"normal\": 5.5,\n                \"elevated\": 6.3,\n                \"high\": 6.5,\n                \"very high\": 8\n                }\n            v = mapping[m.group(1) or m.group(2)] if m else np.nan\n            return v if (not np.isnan(v) and 0 <= v <= 20) else np.nan\n    if not m:\n        outliers[\"hba1c\"].append(t)\n    \n    v = safe_float(m.group(1)) if m else np.nan\n    return v if (not np.isnan(v) and 0 <= v <= 20) else np.nan\n\ndef extract_glucose(text):\n    \"\"\"Extrae glucosa (aleatoria o postprandial) con rango válido 40-600.\"\"\"\n    if not isinstance(text, str):\n        return np.nan\n    t = text.lower()\n    # Preferir \"glucose\" + 2-3 dígitos\n    m = re.search(r'\\bglucose\\b[^0-9]{0,20}(\\d{2,3})(?:\\s*mg/dl)?', t)\n    v = safe_float(m.group(1)) if m else np.nan\n    if not m:\n        pattern = re.compile(\n            r'\\b(?:'\n            r'(?:\\w+\\s+)?glucose(?: (?:level|levels|measurement|measurements|reading|readings))?\\b.{0,10}(?:is|are|was|were|within|of)?\\s*(?P<val>very\\s+high|high|elevated|normal|within normal limits|low|decreased|reduced|abnormal)'\n            r'|'\n            r'(?P<val2>very\\s+high|high|elevated|normal|within normal limits|low|decreased|reduced|abnormal)\\s+(?:\\w+\\s+)?glucose(?: (?:level|levels|measurement|measurements|reading|readings))?'\n            r')\\b',\n            re.IGNORECASE\n        )\n        m = pattern.search(t)\n        if m:\n            mapping = {\n                \"low\": 70,\n                \"normal\": 140,\n                \"within normal limits\": 140,\n                \"elevated\": 165,\n                \"high\": 200,\n                \"abnormal\": 200,\n                \"very high\": 250,\n                }\n            try:\n                v = mapping[m.group(1) or m.group(2)] if m else np.nan\n            except:\n                print(t)\n                exit(0)\n            return v if (not np.isnan(v)) else np.nan\n    if not m:\n        outliers[\"glucose\"].append(t)\n    return v if (not np.isnan(v)) else np.nan\n\ndef extract_flags(text):\n    \"\"\"Extrae hipertensión, cardiopatía, fumación (respeta negaciones).\"\"\"\n    if not isinstance(text, str):\n        return 0, 0, \"unknown\"\n\n    t = text.lower()\n    NEG_PAT = r'(?:no\\s+|without\\s+|denies\\s+|negative\\s+for\\s+|no\\s+history\\s+of\\s+)'\n\n    # Hipertensión: negación > pos\n    hyp_neg = bool(re.search(NEG_PAT + r'(?:hypertension|high\\s+blood\\s+pressure)', t))\n    hyp_pos = bool(re.search(r'\\bhypertension\\b|\\bhigh\\s+blood\\s+pressure\\b', t)) and not hyp_neg\n    has_hypertension = 1 if hyp_pos else 0\n\n    # Cardiopatía: negación > pos\n    hd_neg = bool(re.search(NEG_PAT + r'(?:heart\\s+disease|cardiovascular)', t))\n    hd_pos = bool(re.search(r'\\bheart\\s+disease\\b|\\bcardiovascular', t)) and not hd_neg\n    has_heart_disease = 1 if hd_pos else 0\n\n    # Fumación\n    if re.search(r'\\bnon-smoker\\b|\\bnever\\s+smoked\\b', t):\n        smoking = \"never\"\n    elif re.search(r'\\b(?:past|former)\\s+(?:smoker|smoking)\\b', t):\n        smoking = \"past\"\n    elif re.search(r'\\bcurrent\\s+smoker\\b|\\bis\\s+a\\s+smoker\\b|\\bsmoker\\b', t):\n        smoking = \"current\"\n    else:\n        smoking = \"unknown\"\n\n    return has_hypertension, has_heart_disease, smoking\n\n# TEST: verificar extracción en muestra\nimport numpy as np\n\nfor i in range(min(3, len(df_train_raw))):\n    note = df_train_raw[\"medical_note\"].iloc[i]\n    age = extract_age(note)\n    gender = extract_gender(note)\n    bmi = extract_bmi(note)\n    hba1c = extract_hba1c(note)\n    glucose = extract_glucose(note)\n    hyp, hd, smoking = extract_flags(note)\n\n    age_s    = \"NaN\" if (age is None or (isinstance(age, float) and np.isnan(age))) else f\"{int(age)}\"\n    bmi_s    = \"NaN\" if (bmi is None or np.isnan(bmi)) else f\"{bmi:.1f}\"\n    hba1c_s  = \"NaN\" if (hba1c is None or np.isnan(hba1c)) else f\"{hba1c:.1f}\"\n    glucose_s= \"NaN\" if (glucose is None or np.isnan(glucose)) else f\"{glucose:.0f}\"\n\n    print(\n        f\"\\n  [{i}] age={age_s}, gender={gender}, bmi={bmi_s}, \"\n        f\"hba1c={hba1c_s}, glucose={glucose_s}, hyp={hyp}, hd={hd}, smoking={smoking}\"\n    )\n\n\nprint(\"\\n✅ Extracción verificada\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T18:42:03.880241Z","iopub.execute_input":"2025-11-04T18:42:03.880580Z","iopub.status.idle":"2025-11-04T18:42:03.907532Z","shell.execute_reply.started":"2025-11-04T18:42:03.880558Z","shell.execute_reply":"2025-11-04T18:42:03.906609Z"}},"outputs":[{"name":"stdout","text":"\n  [0] age=16, gender=female, bmi=21.5, hba1c=6.2, glucose=140, hyp=0, hd=1, smoking=never\n\n  [1] age=15, gender=female, bmi=33.6, hba1c=5.5, glucose=158, hyp=1, hd=1, smoking=unknown\n\n  [2] age=54, gender=male, bmi=21.5, hba1c=5.5, glucose=145, hyp=0, hd=1, smoking=current\n\n✅ Extracción verificada\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Aplicar a TRAIN\nprint(\"\\n Train: extrayendo features...\")\ndf_train_raw[\"age\"] = df_train_raw[\"medical_note\"].apply(extract_age)\ndf_train_raw[\"gender\"] = df_train_raw[\"medical_note\"].apply(extract_gender)\ndf_train_raw[\"bmi\"] = df_train_raw[\"medical_note\"].apply(extract_bmi)\ndf_train_raw[\"hba1c\"] = df_train_raw[\"medical_note\"].apply(extract_hba1c)\ndf_train_raw[\"glucose\"] = df_train_raw[\"medical_note\"].apply(extract_glucose)\n\ntmp_train = df_train_raw[\"medical_note\"].apply(extract_flags)\ndf_train_raw[\"has_hypertension\"] = [t[0] for t in tmp_train]\ndf_train_raw[\"has_heart_disease\"] = [t[1] for t in tmp_train]\ndf_train_raw[\"smoking_status\"] = [t[2] for t in tmp_train]\n\n# Aplicar a TEST\nprint(\" Test: extrayendo features...\")\ndf_test_raw[\"age\"] = df_test_raw[\"medical_note\"].apply(extract_age)\ndf_test_raw[\"gender\"] = df_test_raw[\"medical_note\"].apply(extract_gender)\ndf_test_raw[\"bmi\"] = df_test_raw[\"medical_note\"].apply(extract_bmi)\ndf_test_raw[\"hba1c\"] = df_test_raw[\"medical_note\"].apply(extract_hba1c)\ndf_test_raw[\"glucose\"] = df_test_raw[\"medical_note\"].apply(extract_glucose)\n\ntmp_test = df_test_raw[\"medical_note\"].apply(extract_flags)\ndf_test_raw[\"has_hypertension\"] = [t[0] for t in tmp_test]\ndf_test_raw[\"has_heart_disease\"] = [t[1] for t in tmp_test]\ndf_test_raw[\"smoking_status\"] = [t[2] for t in tmp_test]\n\nprint(\"\\n Features extraídos correctamente\")\nprint(f\"\\n MUESTRA TRAIN (primeras 3 filas):\")\ncols = ['patient_id', 'age', 'gender', 'bmi', 'hba1c', 'glucose', 'smoking_status', 'has_diabetes']\nprint(df_train_raw[cols].head(3))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T18:42:04.054035Z","iopub.execute_input":"2025-11-04T18:42:04.054382Z","iopub.status.idle":"2025-11-04T18:42:04.540499Z","shell.execute_reply.started":"2025-11-04T18:42:04.054357Z","shell.execute_reply":"2025-11-04T18:42:04.539672Z"}},"outputs":[{"name":"stdout","text":"\n Train: extrayendo features...\n Test: extrayendo features...\n\n Features extraídos correctamente\n\n MUESTRA TRAIN (primeras 3 filas):\n   patient_id   age  gender    bmi  hba1c  glucose smoking_status  \\\n0       82555  16.0  female  21.49    6.2    140.0          never   \n1       92299  15.0  female  33.62    5.5    158.0        unknown   \n2       18725  54.0    male  21.46    5.5    145.0        current   \n\n   has_diabetes  \n0             0  \n1             0  \n2             0  \n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## 3️⃣ BioClinicalBERT: Generar Embeddings (768-dim)","metadata":{}},{"cell_type":"code","source":"def load_bioclinicalbert():\n    \"\"\"Carga Bio_ClinicalBERT desde HuggingFace.\"\"\"\n    model_name = \"emilyalsentzer/Bio_ClinicalBERT\" # coge el modelo de HuggingFace\n    print(f\" Cargando {model_name}...\")\n    tokenizer = AutoTokenizer.from_pretrained(model_name) # convierte el texto en tokens\n    model = AutoModel.from_pretrained(model_name) # Genera los embeddings desde la red a los token de la secuencia\n    model.eval() # evalua que se ha pasado de texto a embeddings\n    model.to(device) # mueve el modelo a GPU (kaggle)\n    return tokenizer, model\n\ndef mean_pool(last_hidden_state, attention_mask):\n    \"\"\"Mean pooling con mask.\"\"\"\n    mask = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float() # mascara que ve cuales partes de los valores del vector influyeno o no \n    sum_hidden = (last_hidden_state * mask).sum(dim=1) # quita los insignificantes y sumas todos los buenos\n    sum_mask = torch.clamp(mask.sum(dim=1), min=1e-9) # clump evita que se divida en la siguiente linea entre 0 \n    return sum_hidden / sum_mask # calcula la media de todos los tokens entre los de la mascara\n\ndef embed_text(text, tokenizer, model, max_length=512):\n    \"\"\"Genera 1 embedding de 768 dims para un texto si esta vacia o no es texto.\"\"\"\n    if not isinstance(text, str) or len(text.strip()) == 0: \n        return np.zeros(768, dtype=np.float32) \n\n    tokens = tokenizer(text,padding=True,truncation=True,max_length=max_length,return_tensors=\"pt\").to(device) # crea los tokens desde la frase\n\n    with torch.no_grad(): # sin gradientes para no entrenar modelo\n        output = model(**tokens) # crea los embeddings\n        pooled = mean_pool(output.last_hidden_state, tokens[\"attention_mask\"]) # llama a la funcion de la mascara para ponderar correctamente\n\n    return pooled.cpu().numpy()[0].astype(np.float32)\n\n# Cargar modelo (una sola vez)\ntokenizer, model = load_bioclinicalbert()\n\n# Generar embeddings TRAIN\nprint(\"\\n Generando embeddings TRAIN...\")\ntrain_embeddings = []\nfor note in tqdm(df_train_raw[\"medical_note\"].tolist(), desc=\"Train embeddings\", total=len(df_train_raw)):\n    emb = embed_text(note, tokenizer, model)\n    train_embeddings.append(emb)\n\ndf_train_raw[\"embedding\"] = train_embeddings\n\n# Generar embeddings TEST\nprint(\"\\n Generando embeddings TEST...\")\ntest_embeddings = []\nfor note in tqdm(df_test_raw[\"medical_note\"].tolist(), desc=\"Test embeddings\", total=len(df_test_raw)):\n    emb = embed_text(note, tokenizer, model)\n    test_embeddings.append(emb)\n\ndf_test_raw[\"embedding\"] = test_embeddings\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T18:42:08.310178Z","iopub.execute_input":"2025-11-04T18:42:08.310748Z","iopub.status.idle":"2025-11-04T18:42:53.368057Z","shell.execute_reply.started":"2025-11-04T18:42:08.310722Z","shell.execute_reply":"2025-11-04T18:42:53.367237Z"}},"outputs":[{"name":"stdout","text":" Cargando emilyalsentzer/Bio_ClinicalBERT...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0214d6c4312548149b7204fe09aa3625"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9d7375599534fc4af5074dcf4362f3b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ac0a762792f45a6872df1e00e301391"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0b5ffc2a6cf40dda3f0ad4c2628e467"}},"metadata":{}},{"name":"stdout","text":"\n Generando embeddings TRAIN...\n","output_type":"stream"},{"name":"stderr","text":"\nTrain embeddings:   0%|          | 0/3000 [00:00<?, ?it/s]\u001b[A\nTrain embeddings:   0%|          | 1/3000 [00:00<24:06,  2.07it/s]\u001b[A\nTrain embeddings:   0%|          | 5/3000 [00:00<04:48, 10.37it/s]\u001b[A\nTrain embeddings:   0%|          | 9/3000 [00:00<02:53, 17.19it/s]\u001b[A\nTrain embeddings:   0%|          | 12/3000 [00:00<02:32, 19.53it/s]\u001b[A\nTrain embeddings:   1%|          | 16/3000 [00:00<02:05, 23.84it/s]\u001b[A\nTrain embeddings:   1%|          | 22/3000 [00:01<01:32, 32.18it/s]\u001b[A\nTrain embeddings:   1%|          | 26/3000 [00:01<01:28, 33.53it/s]\u001b[A\nTrain embeddings:   1%|          | 30/3000 [00:01<01:29, 33.24it/s]\u001b[A\nTrain embeddings:   1%|          | 35/3000 [00:01<01:21, 36.32it/s]\u001b[A\nTrain embeddings:   1%|▏         | 40/3000 [00:01<01:17, 38.11it/s]\u001b[A\nTrain embeddings:   2%|▏         | 48/3000 [00:01<01:02, 47.09it/s]\u001b[A\nTrain embeddings:   2%|▏         | 56/3000 [00:01<00:53, 55.50it/s]\u001b[A\nTrain embeddings:   2%|▏         | 65/3000 [00:01<00:46, 63.65it/s]\u001b[A\nTrain embeddings:   2%|▎         | 75/3000 [00:01<00:40, 72.22it/s]\u001b[A\nTrain embeddings:   3%|▎         | 85/3000 [00:02<00:37, 78.67it/s]\u001b[A\nTrain embeddings:   3%|▎         | 95/3000 [00:02<00:34, 83.39it/s]\u001b[A\nTrain embeddings:   4%|▎         | 105/3000 [00:02<00:33, 86.64it/s]\u001b[A\nTrain embeddings:   4%|▍         | 115/3000 [00:02<00:32, 88.31it/s]\u001b[A\nTrain embeddings:   4%|▍         | 125/3000 [00:02<00:32, 89.48it/s]\u001b[A\nTrain embeddings:   4%|▍         | 135/3000 [00:02<00:31, 90.67it/s]\u001b[A\nTrain embeddings:   5%|▍         | 145/3000 [00:02<00:31, 91.72it/s]\u001b[A\nTrain embeddings:   5%|▌         | 155/3000 [00:02<00:30, 93.88it/s]\u001b[A\nTrain embeddings:   6%|▌         | 165/3000 [00:02<00:30, 92.87it/s]\u001b[A\nTrain embeddings:   6%|▌         | 175/3000 [00:03<00:31, 90.11it/s]\u001b[A\nTrain embeddings:   6%|▌         | 185/3000 [00:03<00:30, 91.89it/s]\u001b[A\nTrain embeddings:   6%|▋         | 195/3000 [00:03<00:30, 91.39it/s]\u001b[A\nTrain embeddings:   7%|▋         | 205/3000 [00:03<00:30, 91.31it/s]\u001b[A\nTrain embeddings:   7%|▋         | 215/3000 [00:03<00:30, 91.17it/s]\u001b[A\nTrain embeddings:   8%|▊         | 225/3000 [00:03<00:30, 91.71it/s]\u001b[A\nTrain embeddings:   8%|▊         | 235/3000 [00:03<00:31, 88.62it/s]\u001b[A\nTrain embeddings:   8%|▊         | 244/3000 [00:03<00:31, 86.23it/s]\u001b[A\nTrain embeddings:   8%|▊         | 253/3000 [00:03<00:31, 87.06it/s]\u001b[A\nTrain embeddings:   9%|▉         | 263/3000 [00:04<00:30, 89.70it/s]\u001b[A\nTrain embeddings:   9%|▉         | 273/3000 [00:04<00:30, 90.87it/s]\u001b[A\nTrain embeddings:   9%|▉         | 283/3000 [00:04<00:30, 90.45it/s]\u001b[A\nTrain embeddings:  10%|▉         | 293/3000 [00:04<00:29, 90.92it/s]\u001b[A\nTrain embeddings:  10%|█         | 303/3000 [00:04<00:29, 91.15it/s]\u001b[A\nTrain embeddings:  10%|█         | 313/3000 [00:04<00:29, 92.28it/s]\u001b[A\nTrain embeddings:  11%|█         | 323/3000 [00:04<00:28, 92.86it/s]\u001b[A\nTrain embeddings:  11%|█         | 333/3000 [00:04<00:29, 91.40it/s]\u001b[A\nTrain embeddings:  11%|█▏        | 343/3000 [00:04<00:28, 92.69it/s]\u001b[A\nTrain embeddings:  12%|█▏        | 353/3000 [00:04<00:28, 94.33it/s]\u001b[A\nTrain embeddings:  12%|█▏        | 363/3000 [00:05<00:27, 95.91it/s]\u001b[A\nTrain embeddings:  12%|█▏        | 373/3000 [00:05<00:27, 96.70it/s]\u001b[A\nTrain embeddings:  13%|█▎        | 383/3000 [00:05<00:26, 97.38it/s]\u001b[A\nTrain embeddings:  13%|█▎        | 393/3000 [00:05<00:27, 95.66it/s]\u001b[A\nTrain embeddings:  13%|█▎        | 403/3000 [00:05<00:27, 95.58it/s]\u001b[A\nTrain embeddings:  14%|█▍        | 414/3000 [00:05<00:26, 97.90it/s]\u001b[A\nTrain embeddings:  14%|█▍        | 424/3000 [00:05<00:27, 95.33it/s]\u001b[A\nTrain embeddings:  14%|█▍        | 434/3000 [00:05<00:27, 94.33it/s]\u001b[A\nTrain embeddings:  15%|█▍        | 444/3000 [00:05<00:27, 92.44it/s]\u001b[A\nTrain embeddings:  15%|█▌        | 454/3000 [00:06<00:28, 90.20it/s]\u001b[A\nTrain embeddings:  15%|█▌        | 464/3000 [00:06<00:30, 83.85it/s]\u001b[A\nTrain embeddings:  16%|█▌        | 473/3000 [00:06<00:30, 81.98it/s]\u001b[A\nTrain embeddings:  16%|█▌        | 482/3000 [00:06<00:31, 80.45it/s]\u001b[A\nTrain embeddings:  16%|█▋        | 491/3000 [00:06<00:31, 79.75it/s]\u001b[A\nTrain embeddings:  17%|█▋        | 500/3000 [00:06<00:31, 79.47it/s]\u001b[A\nTrain embeddings:  17%|█▋        | 508/3000 [00:06<00:31, 78.83it/s]\u001b[A\nTrain embeddings:  17%|█▋        | 516/3000 [00:06<00:32, 76.56it/s]\u001b[A\nTrain embeddings:  17%|█▋        | 524/3000 [00:06<00:33, 74.50it/s]\u001b[A\nTrain embeddings:  18%|█▊        | 532/3000 [00:07<00:33, 73.38it/s]\u001b[A\nTrain embeddings:  18%|█▊        | 540/3000 [00:07<00:33, 73.35it/s]\u001b[A\nTrain embeddings:  18%|█▊        | 549/3000 [00:07<00:31, 77.36it/s]\u001b[A\nTrain embeddings:  19%|█▊        | 559/3000 [00:07<00:29, 82.83it/s]\u001b[A\nTrain embeddings:  19%|█▉        | 568/3000 [00:07<00:28, 84.76it/s]\u001b[A\nTrain embeddings:  19%|█▉        | 578/3000 [00:07<00:27, 87.28it/s]\u001b[A\nTrain embeddings:  20%|█▉        | 587/3000 [00:07<00:27, 87.82it/s]\u001b[A\nTrain embeddings:  20%|█▉        | 597/3000 [00:07<00:26, 89.31it/s]\u001b[A\nTrain embeddings:  20%|██        | 606/3000 [00:07<00:27, 88.07it/s]\u001b[A\nTrain embeddings:  21%|██        | 616/3000 [00:08<00:26, 90.30it/s]\u001b[A\nTrain embeddings:  21%|██        | 626/3000 [00:08<00:26, 90.81it/s]\u001b[A\nTrain embeddings:  21%|██        | 636/3000 [00:08<00:27, 86.81it/s]\u001b[A\nTrain embeddings:  22%|██▏       | 645/3000 [00:08<00:27, 86.70it/s]\u001b[A\nTrain embeddings:  22%|██▏       | 654/3000 [00:08<00:27, 86.60it/s]\u001b[A\nTrain embeddings:  22%|██▏       | 663/3000 [00:08<00:26, 87.24it/s]\u001b[A\nTrain embeddings:  22%|██▏       | 672/3000 [00:08<00:27, 84.83it/s]\u001b[A\nTrain embeddings:  23%|██▎       | 682/3000 [00:08<00:26, 86.71it/s]\u001b[A\nTrain embeddings:  23%|██▎       | 691/3000 [00:08<00:26, 86.71it/s]\u001b[A\nTrain embeddings:  23%|██▎       | 700/3000 [00:09<00:26, 86.42it/s]\u001b[A\nTrain embeddings:  24%|██▎       | 710/3000 [00:09<00:25, 90.17it/s]\u001b[A\nTrain embeddings:  24%|██▍       | 720/3000 [00:09<00:25, 90.41it/s]\u001b[A\nTrain embeddings:  24%|██▍       | 730/3000 [00:09<00:24, 90.93it/s]\u001b[A\nTrain embeddings:  25%|██▍       | 740/3000 [00:09<00:24, 91.19it/s]\u001b[A\nTrain embeddings:  25%|██▌       | 750/3000 [00:09<00:25, 87.82it/s]\u001b[A\nTrain embeddings:  25%|██▌       | 760/3000 [00:09<00:25, 89.33it/s]\u001b[A\nTrain embeddings:  26%|██▌       | 769/3000 [00:09<00:25, 88.05it/s]\u001b[A\nTrain embeddings:  26%|██▌       | 778/3000 [00:09<00:25, 88.11it/s]\u001b[A\nTrain embeddings:  26%|██▌       | 787/3000 [00:09<00:25, 88.07it/s]\u001b[A\nTrain embeddings:  27%|██▋       | 797/3000 [00:10<00:24, 88.46it/s]\u001b[A\nTrain embeddings:  27%|██▋       | 806/3000 [00:10<00:25, 86.58it/s]\u001b[A\nTrain embeddings:  27%|██▋       | 816/3000 [00:10<00:24, 87.99it/s]\u001b[A\nTrain embeddings:  28%|██▊       | 825/3000 [00:10<00:24, 87.32it/s]\u001b[A\nTrain embeddings:  28%|██▊       | 835/3000 [00:10<00:24, 87.80it/s]\u001b[A\nTrain embeddings:  28%|██▊       | 845/3000 [00:10<00:24, 88.89it/s]\u001b[A\nTrain embeddings:  28%|██▊       | 855/3000 [00:10<00:23, 89.87it/s]\u001b[A\nTrain embeddings:  29%|██▉       | 865/3000 [00:10<00:23, 92.28it/s]\u001b[A\nTrain embeddings:  29%|██▉       | 875/3000 [00:10<00:23, 91.16it/s]\u001b[A\nTrain embeddings:  30%|██▉       | 885/3000 [00:11<00:23, 90.73it/s]\u001b[A\nTrain embeddings:  30%|██▉       | 895/3000 [00:11<00:22, 92.24it/s]\u001b[A\nTrain embeddings:  30%|███       | 905/3000 [00:11<00:22, 91.14it/s]\u001b[A\nTrain embeddings:  30%|███       | 915/3000 [00:11<00:22, 92.91it/s]\u001b[A\nTrain embeddings:  31%|███       | 925/3000 [00:11<00:22, 93.69it/s]\u001b[A\nTrain embeddings:  31%|███       | 935/3000 [00:11<00:21, 94.30it/s]\u001b[A\nTrain embeddings:  32%|███▏      | 945/3000 [00:11<00:22, 91.72it/s]\u001b[A\nTrain embeddings:  32%|███▏      | 955/3000 [00:11<00:22, 91.04it/s]\u001b[A\nTrain embeddings:  32%|███▏      | 965/3000 [00:11<00:22, 89.76it/s]\u001b[A\nTrain embeddings:  32%|███▎      | 975/3000 [00:12<00:22, 90.40it/s]\u001b[A\nTrain embeddings:  33%|███▎      | 985/3000 [00:12<00:22, 91.31it/s]\u001b[A\nTrain embeddings:  33%|███▎      | 995/3000 [00:12<00:21, 91.54it/s]\u001b[A\nTrain embeddings:  34%|███▎      | 1005/3000 [00:12<00:22, 89.96it/s]\u001b[A\nTrain embeddings:  34%|███▍      | 1015/3000 [00:12<00:21, 91.80it/s]\u001b[A\nTrain embeddings:  34%|███▍      | 1025/3000 [00:12<00:21, 90.85it/s]\u001b[A\nTrain embeddings:  34%|███▍      | 1035/3000 [00:12<00:21, 91.12it/s]\u001b[A\nTrain embeddings:  35%|███▍      | 1045/3000 [00:12<00:21, 90.55it/s]\u001b[A\nTrain embeddings:  35%|███▌      | 1055/3000 [00:12<00:21, 91.99it/s]\u001b[A\nTrain embeddings:  36%|███▌      | 1065/3000 [00:13<00:21, 90.09it/s]\u001b[A\nTrain embeddings:  36%|███▌      | 1076/3000 [00:13<00:20, 92.23it/s]\u001b[A\nTrain embeddings:  36%|███▌      | 1086/3000 [00:13<00:20, 91.75it/s]\u001b[A\nTrain embeddings:  37%|███▋      | 1096/3000 [00:13<00:20, 92.10it/s]\u001b[A\nTrain embeddings:  37%|███▋      | 1106/3000 [00:13<00:21, 89.46it/s]\u001b[A\nTrain embeddings:  37%|███▋      | 1115/3000 [00:13<00:21, 87.89it/s]\u001b[A\nTrain embeddings:  37%|███▋      | 1124/3000 [00:13<00:22, 84.78it/s]\u001b[A\nTrain embeddings:  38%|███▊      | 1134/3000 [00:13<00:21, 86.85it/s]\u001b[A\nTrain embeddings:  38%|███▊      | 1144/3000 [00:13<00:21, 88.33it/s]\u001b[A\nTrain embeddings:  38%|███▊      | 1154/3000 [00:14<00:20, 91.02it/s]\u001b[A\nTrain embeddings:  39%|███▉      | 1164/3000 [00:14<00:20, 90.51it/s]\u001b[A\nTrain embeddings:  39%|███▉      | 1174/3000 [00:14<00:20, 91.30it/s]\u001b[A\nTrain embeddings:  39%|███▉      | 1184/3000 [00:14<00:19, 92.45it/s]\u001b[A\nTrain embeddings:  40%|███▉      | 1194/3000 [00:14<00:19, 94.11it/s]\u001b[A\nTrain embeddings:  40%|████      | 1204/3000 [00:14<00:19, 94.08it/s]\u001b[A\nTrain embeddings:  40%|████      | 1214/3000 [00:14<00:19, 93.54it/s]\u001b[A\nTrain embeddings:  41%|████      | 1224/3000 [00:14<00:18, 95.07it/s]\u001b[A\nTrain embeddings:  41%|████      | 1234/3000 [00:14<00:18, 95.32it/s]\u001b[A\nTrain embeddings:  41%|████▏     | 1244/3000 [00:14<00:18, 94.62it/s]\u001b[A\nTrain embeddings:  42%|████▏     | 1254/3000 [00:15<00:18, 93.84it/s]\u001b[A\nTrain embeddings:  42%|████▏     | 1264/3000 [00:15<00:19, 91.32it/s]\u001b[A\nTrain embeddings:  42%|████▏     | 1274/3000 [00:15<00:18, 93.73it/s]\u001b[A\nTrain embeddings:  43%|████▎     | 1284/3000 [00:15<00:18, 93.95it/s]\u001b[A\nTrain embeddings:  43%|████▎     | 1294/3000 [00:15<00:17, 95.07it/s]\u001b[A\nTrain embeddings:  43%|████▎     | 1304/3000 [00:15<00:17, 94.65it/s]\u001b[A\nTrain embeddings:  44%|████▍     | 1314/3000 [00:15<00:18, 93.23it/s]\u001b[A\nTrain embeddings:  44%|████▍     | 1324/3000 [00:15<00:17, 94.49it/s]\u001b[A\nTrain embeddings:  44%|████▍     | 1334/3000 [00:15<00:17, 95.16it/s]\u001b[A\nTrain embeddings:  45%|████▍     | 1344/3000 [00:16<00:17, 94.81it/s]\u001b[A\nTrain embeddings:  45%|████▌     | 1354/3000 [00:16<00:17, 94.66it/s]\u001b[A\nTrain embeddings:  45%|████▌     | 1364/3000 [00:16<00:17, 94.17it/s]\u001b[A\nTrain embeddings:  46%|████▌     | 1374/3000 [00:16<00:17, 94.93it/s]\u001b[A\nTrain embeddings:  46%|████▌     | 1384/3000 [00:16<00:17, 94.53it/s]\u001b[A\nTrain embeddings:  46%|████▋     | 1394/3000 [00:16<00:17, 94.23it/s]\u001b[A\nTrain embeddings:  47%|████▋     | 1404/3000 [00:16<00:16, 94.79it/s]\u001b[A\nTrain embeddings:  47%|████▋     | 1414/3000 [00:16<00:16, 94.00it/s]\u001b[A\nTrain embeddings:  47%|████▋     | 1424/3000 [00:16<00:17, 91.52it/s]\u001b[A\nTrain embeddings:  48%|████▊     | 1434/3000 [00:17<00:17, 91.38it/s]\u001b[A\nTrain embeddings:  48%|████▊     | 1444/3000 [00:17<00:16, 92.08it/s]\u001b[A\nTrain embeddings:  48%|████▊     | 1454/3000 [00:17<00:16, 92.05it/s]\u001b[A\nTrain embeddings:  49%|████▉     | 1464/3000 [00:17<00:16, 91.49it/s]\u001b[A\nTrain embeddings:  49%|████▉     | 1474/3000 [00:17<00:16, 93.15it/s]\u001b[A\nTrain embeddings:  49%|████▉     | 1484/3000 [00:17<00:16, 92.63it/s]\u001b[A\nTrain embeddings:  50%|████▉     | 1494/3000 [00:17<00:16, 93.33it/s]\u001b[A\nTrain embeddings:  50%|█████     | 1504/3000 [00:17<00:16, 92.18it/s]\u001b[A\nTrain embeddings:  50%|█████     | 1514/3000 [00:17<00:16, 91.85it/s]\u001b[A\nTrain embeddings:  51%|█████     | 1524/3000 [00:17<00:15, 93.27it/s]\u001b[A\nTrain embeddings:  51%|█████     | 1534/3000 [00:18<00:15, 93.22it/s]\u001b[A\nTrain embeddings:  51%|█████▏    | 1544/3000 [00:18<00:15, 92.13it/s]\u001b[A\nTrain embeddings:  52%|█████▏    | 1554/3000 [00:18<00:15, 92.04it/s]\u001b[A\nTrain embeddings:  52%|█████▏    | 1564/3000 [00:18<00:15, 93.49it/s]\u001b[A\nTrain embeddings:  52%|█████▏    | 1574/3000 [00:18<00:15, 94.28it/s]\u001b[A\nTrain embeddings:  53%|█████▎    | 1584/3000 [00:18<00:15, 93.76it/s]\u001b[A\nTrain embeddings:  53%|█████▎    | 1594/3000 [00:18<00:15, 93.17it/s]\u001b[A\nTrain embeddings:  53%|█████▎    | 1604/3000 [00:18<00:15, 91.98it/s]\u001b[A\nTrain embeddings:  54%|█████▍    | 1614/3000 [00:18<00:14, 92.47it/s]\u001b[A\nTrain embeddings:  54%|█████▍    | 1624/3000 [00:19<00:14, 92.62it/s]\u001b[A\nTrain embeddings:  54%|█████▍    | 1634/3000 [00:19<00:15, 90.83it/s]\u001b[A\nTrain embeddings:  55%|█████▍    | 1644/3000 [00:19<00:14, 92.48it/s]\u001b[A\nTrain embeddings:  55%|█████▌    | 1654/3000 [00:19<00:14, 93.80it/s]\u001b[A\nTrain embeddings:  55%|█████▌    | 1664/3000 [00:19<00:14, 94.59it/s]\u001b[A\nTrain embeddings:  56%|█████▌    | 1674/3000 [00:19<00:13, 95.07it/s]\u001b[A\nTrain embeddings:  56%|█████▌    | 1684/3000 [00:19<00:13, 95.43it/s]\u001b[A\nTrain embeddings:  56%|█████▋    | 1694/3000 [00:19<00:13, 95.44it/s]\u001b[A\nTrain embeddings:  57%|█████▋    | 1704/3000 [00:19<00:13, 96.02it/s]\u001b[A\nTrain embeddings:  57%|█████▋    | 1714/3000 [00:20<00:13, 93.88it/s]\u001b[A\nTrain embeddings:  57%|█████▋    | 1724/3000 [00:20<00:13, 93.69it/s]\u001b[A\nTrain embeddings:  58%|█████▊    | 1734/3000 [00:20<00:13, 95.09it/s]\u001b[A\nTrain embeddings:  58%|█████▊    | 1744/3000 [00:20<00:13, 94.19it/s]\u001b[A\nTrain embeddings:  58%|█████▊    | 1754/3000 [00:20<00:13, 93.27it/s]\u001b[A\nTrain embeddings:  59%|█████▉    | 1764/3000 [00:20<00:13, 91.64it/s]\u001b[A\nTrain embeddings:  59%|█████▉    | 1774/3000 [00:20<00:13, 91.99it/s]\u001b[A\nTrain embeddings:  59%|█████▉    | 1784/3000 [00:20<00:13, 90.02it/s]\u001b[A\nTrain embeddings:  60%|█████▉    | 1794/3000 [00:20<00:13, 89.80it/s]\u001b[A\nTrain embeddings:  60%|██████    | 1803/3000 [00:21<00:13, 88.32it/s]\u001b[A\nTrain embeddings:  60%|██████    | 1813/3000 [00:21<00:13, 90.21it/s]\u001b[A\nTrain embeddings:  61%|██████    | 1823/3000 [00:21<00:13, 90.51it/s]\u001b[A\nTrain embeddings:  61%|██████    | 1833/3000 [00:21<00:12, 90.90it/s]\u001b[A\nTrain embeddings:  61%|██████▏   | 1843/3000 [00:21<00:12, 91.78it/s]\u001b[A\nTrain embeddings:  62%|██████▏   | 1853/3000 [00:21<00:12, 92.26it/s]\u001b[A\nTrain embeddings:  62%|██████▏   | 1863/3000 [00:21<00:12, 93.08it/s]\u001b[A\nTrain embeddings:  62%|██████▏   | 1873/3000 [00:21<00:12, 92.61it/s]\u001b[A\nTrain embeddings:  63%|██████▎   | 1883/3000 [00:21<00:11, 93.50it/s]\u001b[A\nTrain embeddings:  63%|██████▎   | 1893/3000 [00:21<00:11, 92.79it/s]\u001b[A\nTrain embeddings:  63%|██████▎   | 1903/3000 [00:22<00:12, 89.05it/s]\u001b[A\nTrain embeddings:  64%|██████▍   | 1913/3000 [00:22<00:12, 89.69it/s]\u001b[A\nTrain embeddings:  64%|██████▍   | 1923/3000 [00:22<00:11, 90.63it/s]\u001b[A\nTrain embeddings:  64%|██████▍   | 1933/3000 [00:22<00:11, 90.99it/s]\u001b[A\nTrain embeddings:  65%|██████▍   | 1943/3000 [00:22<00:11, 91.86it/s]\u001b[A\nTrain embeddings:  65%|██████▌   | 1953/3000 [00:22<00:11, 91.89it/s]\u001b[A\nTrain embeddings:  65%|██████▌   | 1963/3000 [00:22<00:11, 92.13it/s]\u001b[A\nTrain embeddings:  66%|██████▌   | 1973/3000 [00:22<00:10, 93.64it/s]\u001b[A\nTrain embeddings:  66%|██████▌   | 1983/3000 [00:22<00:11, 92.38it/s]\u001b[A\nTrain embeddings:  66%|██████▋   | 1993/3000 [00:23<00:10, 94.02it/s]\u001b[A\nTrain embeddings:  67%|██████▋   | 2003/3000 [00:23<00:10, 93.53it/s]\u001b[A\nTrain embeddings:  67%|██████▋   | 2013/3000 [00:23<00:10, 94.14it/s]\u001b[A\nTrain embeddings:  67%|██████▋   | 2023/3000 [00:23<00:10, 93.02it/s]\u001b[A\nTrain embeddings:  68%|██████▊   | 2033/3000 [00:23<00:10, 91.59it/s]\u001b[A\nTrain embeddings:  68%|██████▊   | 2043/3000 [00:23<00:10, 92.28it/s]\u001b[A\nTrain embeddings:  68%|██████▊   | 2053/3000 [00:23<00:10, 87.61it/s]\u001b[A\nTrain embeddings:  69%|██████▉   | 2063/3000 [00:23<00:10, 88.91it/s]\u001b[A\nTrain embeddings:  69%|██████▉   | 2072/3000 [00:23<00:10, 87.47it/s]\u001b[A\nTrain embeddings:  69%|██████▉   | 2081/3000 [00:24<00:10, 87.87it/s]\u001b[A\nTrain embeddings:  70%|██████▉   | 2091/3000 [00:24<00:10, 90.02it/s]\u001b[A\nTrain embeddings:  70%|███████   | 2101/3000 [00:24<00:10, 88.80it/s]\u001b[A\nTrain embeddings:  70%|███████   | 2110/3000 [00:24<00:10, 88.72it/s]\u001b[A\nTrain embeddings:  71%|███████   | 2119/3000 [00:24<00:10, 88.05it/s]\u001b[A\nTrain embeddings:  71%|███████   | 2129/3000 [00:24<00:09, 89.70it/s]\u001b[A\nTrain embeddings:  71%|███████▏  | 2138/3000 [00:24<00:09, 88.73it/s]\u001b[A\nTrain embeddings:  72%|███████▏  | 2147/3000 [00:24<00:09, 88.62it/s]\u001b[A\nTrain embeddings:  72%|███████▏  | 2157/3000 [00:24<00:09, 90.13it/s]\u001b[A\nTrain embeddings:  72%|███████▏  | 2167/3000 [00:25<00:09, 90.90it/s]\u001b[A\nTrain embeddings:  73%|███████▎  | 2177/3000 [00:25<00:08, 92.39it/s]\u001b[A\nTrain embeddings:  73%|███████▎  | 2187/3000 [00:25<00:08, 92.44it/s]\u001b[A\nTrain embeddings:  73%|███████▎  | 2197/3000 [00:25<00:08, 92.64it/s]\u001b[A\nTrain embeddings:  74%|███████▎  | 2207/3000 [00:25<00:08, 92.79it/s]\u001b[A\nTrain embeddings:  74%|███████▍  | 2217/3000 [00:25<00:08, 90.97it/s]\u001b[A\nTrain embeddings:  74%|███████▍  | 2228/3000 [00:25<00:08, 93.38it/s]\u001b[A\nTrain embeddings:  75%|███████▍  | 2238/3000 [00:25<00:08, 94.07it/s]\u001b[A\nTrain embeddings:  75%|███████▍  | 2248/3000 [00:25<00:07, 94.62it/s]\u001b[A\nTrain embeddings:  75%|███████▌  | 2258/3000 [00:25<00:07, 94.42it/s]\u001b[A\nTrain embeddings:  76%|███████▌  | 2268/3000 [00:26<00:07, 93.96it/s]\u001b[A\nTrain embeddings:  76%|███████▌  | 2278/3000 [00:26<00:07, 91.11it/s]\u001b[A\nTrain embeddings:  76%|███████▋  | 2288/3000 [00:26<00:08, 88.29it/s]\u001b[A\nTrain embeddings:  77%|███████▋  | 2298/3000 [00:26<00:07, 89.75it/s]\u001b[A\nTrain embeddings:  77%|███████▋  | 2308/3000 [00:26<00:07, 90.35it/s]\u001b[A\nTrain embeddings:  77%|███████▋  | 2318/3000 [00:26<00:07, 91.25it/s]\u001b[A\nTrain embeddings:  78%|███████▊  | 2328/3000 [00:26<00:07, 92.49it/s]\u001b[A\nTrain embeddings:  78%|███████▊  | 2338/3000 [00:26<00:07, 92.96it/s]\u001b[A\nTrain embeddings:  78%|███████▊  | 2348/3000 [00:26<00:06, 93.48it/s]\u001b[A\nTrain embeddings:  79%|███████▊  | 2358/3000 [00:27<00:06, 92.70it/s]\u001b[A\nTrain embeddings:  79%|███████▉  | 2368/3000 [00:27<00:06, 92.81it/s]\u001b[A\nTrain embeddings:  79%|███████▉  | 2378/3000 [00:27<00:06, 93.46it/s]\u001b[A\nTrain embeddings:  80%|███████▉  | 2388/3000 [00:27<00:06, 92.74it/s]\u001b[A\nTrain embeddings:  80%|███████▉  | 2398/3000 [00:27<00:06, 92.69it/s]\u001b[A\nTrain embeddings:  80%|████████  | 2408/3000 [00:27<00:06, 93.13it/s]\u001b[A\nTrain embeddings:  81%|████████  | 2418/3000 [00:27<00:06, 93.59it/s]\u001b[A\nTrain embeddings:  81%|████████  | 2428/3000 [00:27<00:06, 90.83it/s]\u001b[A\nTrain embeddings:  81%|████████▏ | 2438/3000 [00:27<00:06, 90.04it/s]\u001b[A\nTrain embeddings:  82%|████████▏ | 2448/3000 [00:28<00:06, 90.42it/s]\u001b[A\nTrain embeddings:  82%|████████▏ | 2458/3000 [00:28<00:05, 90.82it/s]\u001b[A\nTrain embeddings:  82%|████████▏ | 2468/3000 [00:28<00:05, 91.61it/s]\u001b[A\nTrain embeddings:  83%|████████▎ | 2478/3000 [00:28<00:05, 92.92it/s]\u001b[A\nTrain embeddings:  83%|████████▎ | 2488/3000 [00:28<00:05, 91.99it/s]\u001b[A\nTrain embeddings:  83%|████████▎ | 2498/3000 [00:28<00:05, 92.17it/s]\u001b[A\nTrain embeddings:  84%|████████▎ | 2509/3000 [00:28<00:05, 93.97it/s]\u001b[A\nTrain embeddings:  84%|████████▍ | 2519/3000 [00:28<00:05, 93.49it/s]\u001b[A\nTrain embeddings:  84%|████████▍ | 2529/3000 [00:28<00:05, 93.60it/s]\u001b[A\nTrain embeddings:  85%|████████▍ | 2539/3000 [00:29<00:05, 91.81it/s]\u001b[A\nTrain embeddings:  85%|████████▍ | 2549/3000 [00:29<00:04, 93.89it/s]\u001b[A\nTrain embeddings:  85%|████████▌ | 2559/3000 [00:29<00:04, 92.12it/s]\u001b[A\nTrain embeddings:  86%|████████▌ | 2569/3000 [00:29<00:04, 91.66it/s]\u001b[A\nTrain embeddings:  86%|████████▌ | 2579/3000 [00:29<00:04, 90.25it/s]\u001b[A\nTrain embeddings:  86%|████████▋ | 2589/3000 [00:29<00:04, 91.61it/s]\u001b[A\nTrain embeddings:  87%|████████▋ | 2599/3000 [00:29<00:04, 90.53it/s]\u001b[A\nTrain embeddings:  87%|████████▋ | 2609/3000 [00:29<00:04, 88.15it/s]\u001b[A\nTrain embeddings:  87%|████████▋ | 2619/3000 [00:29<00:04, 89.84it/s]\u001b[A\nTrain embeddings:  88%|████████▊ | 2629/3000 [00:30<00:04, 91.74it/s]\u001b[A\nTrain embeddings:  88%|████████▊ | 2639/3000 [00:30<00:03, 90.71it/s]\u001b[A\nTrain embeddings:  88%|████████▊ | 2649/3000 [00:30<00:03, 93.21it/s]\u001b[A\nTrain embeddings:  89%|████████▊ | 2659/3000 [00:30<00:03, 92.06it/s]\u001b[A\nTrain embeddings:  89%|████████▉ | 2669/3000 [00:30<00:03, 91.31it/s]\u001b[A\nTrain embeddings:  89%|████████▉ | 2679/3000 [00:30<00:03, 93.16it/s]\u001b[A\nTrain embeddings:  90%|████████▉ | 2689/3000 [00:30<00:03, 93.49it/s]\u001b[A\nTrain embeddings:  90%|████████▉ | 2699/3000 [00:30<00:03, 94.09it/s]\u001b[A\nTrain embeddings:  90%|█████████ | 2709/3000 [00:30<00:03, 93.69it/s]\u001b[A\nTrain embeddings:  91%|█████████ | 2719/3000 [00:30<00:03, 91.84it/s]\u001b[A\nTrain embeddings:  91%|█████████ | 2729/3000 [00:31<00:02, 92.08it/s]\u001b[A\nTrain embeddings:  91%|█████████▏| 2739/3000 [00:31<00:02, 91.85it/s]\u001b[A\nTrain embeddings:  92%|█████████▏| 2749/3000 [00:31<00:02, 93.44it/s]\u001b[A\nTrain embeddings:  92%|█████████▏| 2759/3000 [00:31<00:02, 91.66it/s]\u001b[A\nTrain embeddings:  92%|█████████▏| 2769/3000 [00:31<00:02, 91.55it/s]\u001b[A\nTrain embeddings:  93%|█████████▎| 2779/3000 [00:31<00:02, 91.49it/s]\u001b[A\nTrain embeddings:  93%|█████████▎| 2789/3000 [00:31<00:02, 90.39it/s]\u001b[A\nTrain embeddings:  93%|█████████▎| 2799/3000 [00:31<00:02, 92.85it/s]\u001b[A\nTrain embeddings:  94%|█████████▎| 2809/3000 [00:31<00:02, 92.24it/s]\u001b[A\nTrain embeddings:  94%|█████████▍| 2819/3000 [00:32<00:01, 92.76it/s]\u001b[A\nTrain embeddings:  94%|█████████▍| 2829/3000 [00:32<00:01, 92.69it/s]\u001b[A\nTrain embeddings:  95%|█████████▍| 2839/3000 [00:32<00:01, 91.75it/s]\u001b[A\nTrain embeddings:  95%|█████████▍| 2849/3000 [00:32<00:01, 93.09it/s]\u001b[A\nTrain embeddings:  95%|█████████▌| 2859/3000 [00:32<00:01, 93.52it/s]\u001b[A\nTrain embeddings:  96%|█████████▌| 2869/3000 [00:32<00:01, 92.83it/s]\u001b[A\nTrain embeddings:  96%|█████████▌| 2879/3000 [00:32<00:01, 94.67it/s]\u001b[A\nTrain embeddings:  96%|█████████▋| 2889/3000 [00:32<00:01, 95.18it/s]\u001b[A\nTrain embeddings:  97%|█████████▋| 2899/3000 [00:32<00:01, 95.17it/s]\u001b[A\nTrain embeddings:  97%|█████████▋| 2909/3000 [00:33<00:00, 94.68it/s]\u001b[A\nTrain embeddings:  97%|█████████▋| 2919/3000 [00:33<00:00, 88.92it/s]\u001b[A\nTrain embeddings:  98%|█████████▊| 2928/3000 [00:33<00:00, 87.06it/s]\u001b[A\nTrain embeddings:  98%|█████████▊| 2938/3000 [00:33<00:00, 89.78it/s]\u001b[A\nTrain embeddings:  98%|█████████▊| 2948/3000 [00:33<00:00, 87.79it/s]\u001b[A\nTrain embeddings:  99%|█████████▊| 2957/3000 [00:33<00:00, 86.39it/s]\u001b[A\nTrain embeddings:  99%|█████████▉| 2966/3000 [00:33<00:00, 80.38it/s]\u001b[A\nTrain embeddings:  99%|█████████▉| 2976/3000 [00:33<00:00, 82.94it/s]\u001b[A\nTrain embeddings: 100%|█████████▉| 2985/3000 [00:33<00:00, 78.86it/s]\u001b[A\nTrain embeddings: 100%|██████████| 3000/3000 [00:34<00:00, 87.86it/s]\u001b[A\n","output_type":"stream"},{"name":"stdout","text":"\n Generando embeddings TEST...\n","output_type":"stream"},{"name":"stderr","text":"Test embeddings: 100%|██████████| 300/300 [00:03<00:00, 93.91it/s]\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## 4️⃣ Agrupar por Paciente + Expandir Embeddings","metadata":{}},{"cell_type":"code","source":"def most_common(series):\n    \"\"\"Retorna valor más frecuente o 'unknown' del embedding.\"\"\"\n    s = series.dropna()\n    return s.mode().iat[0] if not s.mode().empty else \"unknown\"\n\ndef emb_mean(series):\n    \"\"\"Promedia embeddings.\"\"\"\n    stacked = np.vstack(series.values)\n    return stacked.mean(axis=0)\n\n\n# Agregación TRAIN\nprint(\"\\n Agrupando TRAIN por patient_id...\")\nagg_dict = {\n    \"medical_note\": \"count\",\n    \"has_diabetes\": \"first\",\n    \"age\": \"mean\",\n    \"gender\": most_common,\n    \"bmi\": \"mean\",\n    \"hba1c\": \"mean\",\n    \"glucose\": \"mean\",\n    \"has_hypertension\": \"max\",\n    \"has_heart_disease\": \"max\",\n    \"smoking_status\": most_common,\n    \"embedding\": emb_mean\n}\n\ndf_train_agg = df_train_raw.groupby(\"patient_id\").agg(agg_dict).reset_index() # por si se repiten pacientes, agruparlos\ndf_train_agg.rename(columns={\"medical_note\": \"note_count\"}, inplace=True)\n\nprint(f\" Train agrupado: {df_train_agg.shape[0]} pacientes únicos\")\n\n# Agregación TEST (sin has_diabetes)\nprint(\"\\n Agrupando TEST por patient_id...\")\nagg_dict_test = {\n    \"medical_note\": \"count\",\n    \"age\": \"mean\",\n    \"gender\": most_common,\n    \"bmi\": \"mean\",\n    \"hba1c\": \"mean\",\n    \"glucose\": \"mean\",\n    \"has_hypertension\": \"max\",\n    \"has_heart_disease\": \"max\",\n    \"smoking_status\": most_common,\n    \"embedding\": emb_mean\n}\n\ndf_test_agg = df_test_raw.groupby(\"patient_id\").agg(agg_dict_test).reset_index()\ndf_test_agg.rename(columns={\"medical_note\": \"note_count\"}, inplace=True)\n\nprint(f\" Test agrupado: {df_test_agg.shape[0]} pacientes únicos\")\n\n# Expandir embeddings en columnas\nprint(\"\\n Expandiendo embeddings (768 columnas)...\")\n\nemb_train = np.vstack(df_train_agg[\"embedding\"].values)\nemb_test = np.vstack(df_test_agg[\"embedding\"].values)\n\n# Crea los embeddings (columnas) en el Dataframe\nemb_cols = [f\"emb_{i}\" for i in range(emb_train.shape[1])]\nemb_df_train = pd.DataFrame(emb_train, columns=emb_cols)\nemb_df_test = pd.DataFrame(emb_test, columns=emb_cols)\n\ndf_train_final = pd.concat([df_train_agg.drop(columns=[\"embedding\"]).reset_index(drop=True), emb_df_train], axis=1)\ndf_test_final = pd.concat([df_test_agg.drop(columns=[\"embedding\"]).reset_index(drop=True), emb_df_test], axis=1)\n\nprint(f\"\\n Train final: {df_train_final.shape}\")\nprint(f\" Test final: {df_test_final.shape}\")\n\nprint(f\"\\n PRIMERAS FILAS TRAIN (con age y gender):\")\nprint(df_train_final[['patient_id', 'age', 'gender', 'bmi', 'hba1c', 'glucose', 'smoking_status', 'has_diabetes', 'note_count']].head(5))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T18:42:53.369576Z","iopub.execute_input":"2025-11-04T18:42:53.369818Z","iopub.status.idle":"2025-11-04T18:42:55.277959Z","shell.execute_reply.started":"2025-11-04T18:42:53.369801Z","shell.execute_reply":"2025-11-04T18:42:55.277095Z"}},"outputs":[{"name":"stdout","text":"\n Agrupando TRAIN por patient_id...\n Train agrupado: 3000 pacientes únicos\n\n Agrupando TEST por patient_id...\n Test agrupado: 300 pacientes únicos\n\n Expandiendo embeddings (768 columnas)...\n\n Train final: (3000, 779)\n Test final: (300, 778)\n\n PRIMERAS FILAS TRAIN (con age y gender):\n   patient_id   age  gender    bmi  hba1c  glucose smoking_status  \\\n0           5  23.0    male  21.05    6.5    200.0        current   \n1          14  70.0  female  32.63    5.5    165.0        unknown   \n2          36  42.0  female  31.50    5.8    200.0          never   \n3          67  71.0    male  39.03    6.3      NaN          never   \n4         127  66.0  female  23.58    5.8    145.0          never   \n\n   has_diabetes  note_count  \n0             0           1  \n1             0           1  \n2             0           1  \n3             1           1  \n4             1           1  \n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"df_train_final","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T18:42:55.278759Z","iopub.execute_input":"2025-11-04T18:42:55.279051Z","iopub.status.idle":"2025-11-04T18:42:55.311815Z","shell.execute_reply.started":"2025-11-04T18:42:55.279028Z","shell.execute_reply":"2025-11-04T18:42:55.310965Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"      patient_id  note_count  has_diabetes   age  gender    bmi  hba1c  \\\n0              5           1             0  23.0    male  21.05    6.5   \n1             14           1             0  70.0  female  32.63    5.5   \n2             36           1             0  42.0  female  31.50    5.8   \n3             67           1             1  71.0    male  39.03    6.3   \n4            127           1             1  66.0  female  23.58    5.8   \n...          ...         ...           ...   ...     ...    ...    ...   \n2995       95954           1             0  61.0    male  24.52    6.6   \n2996       96030           1             0  73.0  female  25.07    6.3   \n2997       96035           1             0  18.0    male  37.65    6.5   \n2998       96093           1             1  74.0  female   6.00    6.8   \n2999       96095           1             0  64.0  female  25.48    6.5   \n\n      glucose  has_hypertension  has_heart_disease  ...   emb_758   emb_759  \\\n0       200.0                 0                  1  ...  0.168776 -0.137289   \n1       165.0                 0                  1  ...  0.140446 -0.112927   \n2       200.0                 0                  1  ...  0.144146 -0.082072   \n3         NaN                 0                  1  ...  0.158193 -0.121447   \n4       145.0                 0                  1  ...  0.054226 -0.093798   \n...       ...               ...                ...  ...       ...       ...   \n2995    165.0                 0                  1  ...  0.172905 -0.028232   \n2996    158.0                 0                  1  ...  0.050674 -0.060000   \n2997     90.0                 0                  1  ...  0.141482 -0.078641   \n2998    165.0                 1                  0  ...  0.124343  0.006571   \n2999    140.0                 0                  1  ...  0.085310 -0.102265   \n\n       emb_760   emb_761   emb_762   emb_763   emb_764   emb_765   emb_766  \\\n0    -0.300718  0.055569 -0.012067 -0.191791  0.101528  0.040025 -0.036748   \n1    -0.244349 -0.033866  0.026291 -0.076418  0.078653  0.214932 -0.077384   \n2    -0.269926 -0.027545  0.041318 -0.097104  0.003274  0.072266 -0.098089   \n3    -0.211743 -0.014441 -0.079715 -0.143533  0.071336  0.013479 -0.085260   \n4    -0.332355 -0.064596  0.043048 -0.200588  0.136516  0.041142 -0.021674   \n...        ...       ...       ...       ...       ...       ...       ...   \n2995 -0.289735  0.031709 -0.036546 -0.199922  0.011492  0.098776 -0.031317   \n2996 -0.283743 -0.085756 -0.056065 -0.177056  0.061681  0.067599 -0.042998   \n2997 -0.259597  0.134808  0.033681 -0.146596  0.002997  0.081718  0.014971   \n2998 -0.255402 -0.014538 -0.036401 -0.155102  0.129003  0.092416 -0.071230   \n2999 -0.257324 -0.022427  0.071746 -0.198685  0.103298  0.043273 -0.056627   \n\n       emb_767  \n0    -0.125205  \n1     0.030703  \n2    -0.058813  \n3     0.011425  \n4    -0.084981  \n...        ...  \n2995 -0.044507  \n2996 -0.052660  \n2997 -0.069236  \n2998 -0.012100  \n2999 -0.058333  \n\n[3000 rows x 779 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>patient_id</th>\n      <th>note_count</th>\n      <th>has_diabetes</th>\n      <th>age</th>\n      <th>gender</th>\n      <th>bmi</th>\n      <th>hba1c</th>\n      <th>glucose</th>\n      <th>has_hypertension</th>\n      <th>has_heart_disease</th>\n      <th>...</th>\n      <th>emb_758</th>\n      <th>emb_759</th>\n      <th>emb_760</th>\n      <th>emb_761</th>\n      <th>emb_762</th>\n      <th>emb_763</th>\n      <th>emb_764</th>\n      <th>emb_765</th>\n      <th>emb_766</th>\n      <th>emb_767</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>23.0</td>\n      <td>male</td>\n      <td>21.05</td>\n      <td>6.5</td>\n      <td>200.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.168776</td>\n      <td>-0.137289</td>\n      <td>-0.300718</td>\n      <td>0.055569</td>\n      <td>-0.012067</td>\n      <td>-0.191791</td>\n      <td>0.101528</td>\n      <td>0.040025</td>\n      <td>-0.036748</td>\n      <td>-0.125205</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>14</td>\n      <td>1</td>\n      <td>0</td>\n      <td>70.0</td>\n      <td>female</td>\n      <td>32.63</td>\n      <td>5.5</td>\n      <td>165.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.140446</td>\n      <td>-0.112927</td>\n      <td>-0.244349</td>\n      <td>-0.033866</td>\n      <td>0.026291</td>\n      <td>-0.076418</td>\n      <td>0.078653</td>\n      <td>0.214932</td>\n      <td>-0.077384</td>\n      <td>0.030703</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>36</td>\n      <td>1</td>\n      <td>0</td>\n      <td>42.0</td>\n      <td>female</td>\n      <td>31.50</td>\n      <td>5.8</td>\n      <td>200.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.144146</td>\n      <td>-0.082072</td>\n      <td>-0.269926</td>\n      <td>-0.027545</td>\n      <td>0.041318</td>\n      <td>-0.097104</td>\n      <td>0.003274</td>\n      <td>0.072266</td>\n      <td>-0.098089</td>\n      <td>-0.058813</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>67</td>\n      <td>1</td>\n      <td>1</td>\n      <td>71.0</td>\n      <td>male</td>\n      <td>39.03</td>\n      <td>6.3</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.158193</td>\n      <td>-0.121447</td>\n      <td>-0.211743</td>\n      <td>-0.014441</td>\n      <td>-0.079715</td>\n      <td>-0.143533</td>\n      <td>0.071336</td>\n      <td>0.013479</td>\n      <td>-0.085260</td>\n      <td>0.011425</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>127</td>\n      <td>1</td>\n      <td>1</td>\n      <td>66.0</td>\n      <td>female</td>\n      <td>23.58</td>\n      <td>5.8</td>\n      <td>145.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.054226</td>\n      <td>-0.093798</td>\n      <td>-0.332355</td>\n      <td>-0.064596</td>\n      <td>0.043048</td>\n      <td>-0.200588</td>\n      <td>0.136516</td>\n      <td>0.041142</td>\n      <td>-0.021674</td>\n      <td>-0.084981</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2995</th>\n      <td>95954</td>\n      <td>1</td>\n      <td>0</td>\n      <td>61.0</td>\n      <td>male</td>\n      <td>24.52</td>\n      <td>6.6</td>\n      <td>165.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.172905</td>\n      <td>-0.028232</td>\n      <td>-0.289735</td>\n      <td>0.031709</td>\n      <td>-0.036546</td>\n      <td>-0.199922</td>\n      <td>0.011492</td>\n      <td>0.098776</td>\n      <td>-0.031317</td>\n      <td>-0.044507</td>\n    </tr>\n    <tr>\n      <th>2996</th>\n      <td>96030</td>\n      <td>1</td>\n      <td>0</td>\n      <td>73.0</td>\n      <td>female</td>\n      <td>25.07</td>\n      <td>6.3</td>\n      <td>158.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.050674</td>\n      <td>-0.060000</td>\n      <td>-0.283743</td>\n      <td>-0.085756</td>\n      <td>-0.056065</td>\n      <td>-0.177056</td>\n      <td>0.061681</td>\n      <td>0.067599</td>\n      <td>-0.042998</td>\n      <td>-0.052660</td>\n    </tr>\n    <tr>\n      <th>2997</th>\n      <td>96035</td>\n      <td>1</td>\n      <td>0</td>\n      <td>18.0</td>\n      <td>male</td>\n      <td>37.65</td>\n      <td>6.5</td>\n      <td>90.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.141482</td>\n      <td>-0.078641</td>\n      <td>-0.259597</td>\n      <td>0.134808</td>\n      <td>0.033681</td>\n      <td>-0.146596</td>\n      <td>0.002997</td>\n      <td>0.081718</td>\n      <td>0.014971</td>\n      <td>-0.069236</td>\n    </tr>\n    <tr>\n      <th>2998</th>\n      <td>96093</td>\n      <td>1</td>\n      <td>1</td>\n      <td>74.0</td>\n      <td>female</td>\n      <td>6.00</td>\n      <td>6.8</td>\n      <td>165.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.124343</td>\n      <td>0.006571</td>\n      <td>-0.255402</td>\n      <td>-0.014538</td>\n      <td>-0.036401</td>\n      <td>-0.155102</td>\n      <td>0.129003</td>\n      <td>0.092416</td>\n      <td>-0.071230</td>\n      <td>-0.012100</td>\n    </tr>\n    <tr>\n      <th>2999</th>\n      <td>96095</td>\n      <td>1</td>\n      <td>0</td>\n      <td>64.0</td>\n      <td>female</td>\n      <td>25.48</td>\n      <td>6.5</td>\n      <td>140.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.085310</td>\n      <td>-0.102265</td>\n      <td>-0.257324</td>\n      <td>-0.022427</td>\n      <td>0.071746</td>\n      <td>-0.198685</td>\n      <td>0.103298</td>\n      <td>0.043273</td>\n      <td>-0.056627</td>\n      <td>-0.058333</td>\n    </tr>\n  </tbody>\n</table>\n<p>3000 rows × 779 columns</p>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"## 5️⃣ Análisis Exploratorio (EDA Completo)","metadata":{}},{"cell_type":"code","source":"\n\nprint(f\"\\n EDAD (Age):\")\nprint(f\"   Media: {df_train_final['age'].mean():.1f} años\")\nprint(f\"   Mediana: {df_train_final['age'].median():.1f} años\")\nprint(f\"   Rango: {df_train_final['age'].min():.0f} - {df_train_final['age'].max():.0f} años\")\nprint(f\"   Faltantes: {df_train_final['age'].isna().sum()}\")\n\nprint(f\"\\n GÉNERO (Gender):\")\ngen_dist = df_train_final['gender'].value_counts()\nfor g, c in gen_dist.items():\n    print(f\"   {g}: {c} ({c/len(df_train_final)*100:.1f}%)\")\n\nprint(f\"\\n BMI:\")\nprint(f\"   Media: {df_train_final['bmi'].mean():.2f} ± {df_train_final['bmi'].std():.2f}\")\nprint(f\"   Rango: {df_train_final['bmi'].min():.2f} - {df_train_final['bmi'].max():.2f}\")\nprint(f\"   Faltantes: {df_train_final['bmi'].isna().sum()}\")\n\nprint(f\"\\n HbA1c:\")\nprint(f\"   Media: {df_train_final['hba1c'].mean():.2f} ± {df_train_final['hba1c'].std():.2f}\")\nprint(f\"   Rango: {df_train_final['hba1c'].min():.2f} - {df_train_final['hba1c'].max():.2f}\")\nprint(f\"   Faltantes: {df_train_final['hba1c'].isna().sum()}\")\n\nprint(f\"\\n GLUCOSA (Glucose):\")\nprint(f\"   Media: {df_train_final['glucose'].mean():.2f} ± {df_train_final['glucose'].std():.2f}\")\nprint(f\"   Rango: {df_train_final['glucose'].min():.2f} - {df_train_final['glucose'].max():.2f}\")\nprint(f\"   Faltantes: {df_train_final['glucose'].isna().sum()}\")\n\nprint(f\"\\n HIPERTENSIÓN:\")\nhyp_count = df_train_final['has_hypertension'].sum()\nprint(f\"   Con hipertensión: {hyp_count} ({hyp_count/len(df_train_final)*100:.1f}%)\")\n\nprint(f\"\\n ENFERMEDAD CARDÍACA:\")\nhd_count = df_train_final['has_heart_disease'].sum()\nprint(f\"   Con cardiopatía: {hd_count} ({hd_count/len(df_train_final)*100:.1f}%)\")\n\nprint(f\"\\n FUMACIÓN:\")\nsmoke_dist = df_train_final['smoking_status'].value_counts()\nfor s, c in smoke_dist.items():\n    print(f\"   {s}: {c} ({c/len(df_train_final)*100:.1f}%)\")\n\nprint(f\"\\n DIABETES (TARGET):\")\ndiab_dist = df_train_final['has_diabetes'].value_counts()\nprint(f\"   Negativo (0): {diab_dist[0]} ({diab_dist[0]/len(df_train_final)*100:.1f}%)\")\nprint(f\"   Positivo (1): {diab_dist[1]} ({diab_dist[1]/len(df_train_final)*100:.1f}%)\")\n\nprint(f\"\\n CORRELACIÓN CON DIABETES:\")\nnumeric_cols = ['age', 'bmi', 'hba1c', 'glucose', 'has_hypertension', 'has_heart_disease', 'note_count']\ncorr = df_train_final[numeric_cols + ['has_diabetes']].corr()['has_diabetes'].sort_values(ascending=False)\nprint(corr.head(8))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T18:42:55.313647Z","iopub.execute_input":"2025-11-04T18:42:55.313867Z","iopub.status.idle":"2025-11-04T18:42:55.335091Z","shell.execute_reply.started":"2025-11-04T18:42:55.313851Z","shell.execute_reply":"2025-11-04T18:42:55.334258Z"}},"outputs":[{"name":"stdout","text":"\n EDAD (Age):\n   Media: 46.3 años\n   Mediana: 49.0 años\n   Rango: 1 - 80 años\n   Faltantes: 9\n\n GÉNERO (Gender):\n   female: 1663 (55.4%)\n   male: 1337 (44.6%)\n\n BMI:\n   Media: 28.05 ± 7.77\n   Rango: 0.00 - 72.21\n   Faltantes: 5\n\n HbA1c:\n   Media: 6.25 ± 1.07\n   Rango: 3.50 - 9.00\n   Faltantes: 115\n\n GLUCOSA (Glucose):\n   Media: 161.97 ± 43.13\n   Rango: 15.00 - 300.00\n   Faltantes: 211\n\n HIPERTENSIÓN:\n   Con hipertensión: 1017 (33.9%)\n\n ENFERMEDAD CARDÍACA:\n   Con cardiopatía: 2874 (95.8%)\n\n FUMACIÓN:\n   never: 1566 (52.2%)\n   unknown: 768 (25.6%)\n   past: 552 (18.4%)\n   current: 114 (3.8%)\n\n DIABETES (TARGET):\n   Negativo (0): 2100 (70.0%)\n   Positivo (1): 900 (30.0%)\n\n CORRELACIÓN CON DIABETES:\nhas_diabetes         1.000000\nhba1c                0.535270\nglucose              0.446588\nage                  0.429397\nbmi                  0.315766\nhas_hypertension     0.199608\nhas_heart_disease   -0.062372\nnote_count                NaN\nName: has_diabetes, dtype: float64\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"scaler_bmi = StandardScaler()\nscaler_hba1c = StandardScaler()\nscaler_glucose = StandardScaler()\nscaler_age = StandardScaler()\n\ndf_train_final[\"bmi\"] = scaler_bmi.fit_transform(df_train_final[[\"bmi\"]])\ndf_train_final[\"hba1c\"] = scaler_hba1c.fit_transform(df_train_final[[\"hba1c\"]])\ndf_train_final[\"glucose\"] = scaler_glucose.fit_transform(df_train_final[[\"glucose\"]])\ndf_train_final[\"age\"] = scaler_age.fit_transform(df_train_final[[\"age\"]])\n\ndf_test_final[\"bmi\"] = scaler_bmi.transform(df_test_final[[\"bmi\"]])\ndf_test_final[\"hba1c\"] = scaler_hba1c.transform(df_test_final[[\"hba1c\"]])\ndf_test_final[\"glucose\"] = scaler_glucose.transform(df_test_final[[\"glucose\"]])\ndf_test_final[\"age\"] = scaler_age.transform(df_test_final[[\"age\"]])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T18:42:55.335881Z","iopub.execute_input":"2025-11-04T18:42:55.336127Z","iopub.status.idle":"2025-11-04T18:42:55.364239Z","shell.execute_reply.started":"2025-11-04T18:42:55.336110Z","shell.execute_reply":"2025-11-04T18:42:55.363496Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"## 6️⃣ Preparación para Modelado","metadata":{}},{"cell_type":"code","source":"# Preparar X_train e y_train\nX_train = df_train_final.drop(columns=[\"patient_id\", \"has_diabetes\"])\ny_train = df_train_final[\"has_diabetes\"]\n\n# Preparar X_test\nX_test = df_test_final.drop(columns=[\"patient_id\"])\n\n# Rellenar NaNs\nprint(\"\\n Rellenando valores faltantes...\")\n\nfor col in X_train.columns:\n    if X_train[col].dtype == 'object':\n        # Categóricos: usar moda\n        mode_val = X_train[col].mode()[0] if not X_train[col].mode().empty else \"unknown\"\n        X_train[col] = X_train[col].fillna(mode_val)\n        X_test[col] = X_test[col].fillna(mode_val)\n    else:\n        # Numéricos: usar media\n        mean_val = X_train[col].mean()\n        X_train[col] = X_train[col].fillna(mean_val)\n        X_test[col] = X_test[col].fillna(mean_val)\n\n# One-hot encoding para categorías\nprint(\"\\n One-hot encoding para gender y smoking_status...\")\nX_train = pd.get_dummies(X_train, columns=['gender', 'smoking_status'], drop_first=True)\nX_test = pd.get_dummies(X_test, columns=['gender', 'smoking_status'], drop_first=True)\n\n# Alinear columnas\nfor col in set(X_train.columns) - set(X_test.columns):\n    X_test[col] = 0\nfor col in set(X_test.columns) - set(X_train.columns):\n    X_train[col] = 0\n\nX_train = X_train[sorted(X_train.columns)]\nX_test = X_test[sorted(X_train.columns)]\n\nprint(f\"\\n X_train final shape: {X_train.shape}\")\nprint(f\" X_test final shape: {X_test.shape}\")\nprint(f\"\\n Columnas features: {X_train.columns.tolist()[:15]}... (+{len(X_train.columns)-15})\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T18:42:55.364998Z","iopub.execute_input":"2025-11-04T18:42:55.365221Z","iopub.status.idle":"2025-11-04T18:42:55.832917Z","shell.execute_reply.started":"2025-11-04T18:42:55.365204Z","shell.execute_reply":"2025-11-04T18:42:55.832209Z"}},"outputs":[{"name":"stdout","text":"\n Rellenando valores faltantes...\n\n One-hot encoding para gender y smoking_status...\n\n X_train final shape: (3000, 779)\n X_test final shape: (300, 779)\n\n Columnas features: ['age', 'bmi', 'emb_0', 'emb_1', 'emb_10', 'emb_100', 'emb_101', 'emb_102', 'emb_103', 'emb_104', 'emb_105', 'emb_106', 'emb_107', 'emb_108', 'emb_109']... (+764)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"## 7️⃣ Ensemble con Weighted Soft Voting\n\n\n","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# ===== LIBRERÍAS =====\ntry:\n    from xgboost import XGBClassifier\n    from catboost import CatBoostClassifier\nexcept Exception:\n    from xgboost import XGBClassifier\n    from catboost import CatBoostClassifier\n\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score, f1_score, accuracy_score\nimport numpy as np\n\n# ===== UTILIDADES =====\ndef auc_weights(models, X_tr, y_tr, X_val, y_val):\n    aucs, names, fitted = [], [], []\n    for name, model in models:\n        model.fit(X_tr, y_tr)\n        proba = model.predict_proba(X_val)[:, 1]\n        auc = roc_auc_score(y_val, proba)\n        aucs.append(auc); names.append(name); fitted.append(model)\n        print(f\"{name}: AUC={auc:.4f}\")\n    auc_clipped = np.clip(aucs, 0.5, 1.0)\n    raw = (np.array(auc_clipped) - 0.5) + 1e-6\n    w = (raw / raw.sum()).tolist()\n    print(\"Pesos:\", {n: round(wi,3) for n, wi in zip(names, w)})\n    return list(zip(names, fitted)), w\n\ndef report(name, model, X_val, y_val):\n    y_hat = model.predict(X_val)\n    y_pb  = model.predict_proba(X_val)[:, 1]\n    auc = roc_auc_score(y_val, y_pb)\n    f1  = f1_score(y_val, y_hat, zero_division=0)\n    acc = accuracy_score(y_val, y_hat)\n    print(f\"[{name}] AUC={auc:.4f}  F1={f1:.4f}  Acc={acc:.4f}\")\n\n# ===== PREPARACIÓN DE LOS DATOS =====\n# Aquí debes asegurarte de que X_train y y_train ya están preparados previamente en tu código\n\n# Divide el conjunto de datos en entrenamiento y validación\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n\n# Ratio de desbalance\npos = max(1, int(y_train.sum()))\nneg = int(len(y_train) - pos)\nspw = neg / pos\nprint(f\"scale_pos_weight={spw:.2f}\")\n\n# ===== META-MODELO PARA STACKING =====\nmeta_lr = LogisticRegression(max_iter=2000, solver='lbfgs', class_weight='balanced', C=0.5, random_state=42)\n\n# ===== CATB + XGB + SVM =====\ncatb_opt = CatBoostClassifier(\n    iterations=200, depth=6, learning_rate=0.05, l2_leaf_reg=3.0,\n    loss_function='Logloss', eval_metric='Logloss', class_weights=[1.0, spw],\n    random_state=42, verbose=0  # Menor número de iteraciones\n)\n\nxgb_opt = XGBClassifier(\n    n_estimators=200, max_depth=5, learning_rate=0.03,\n    subsample=0.8, colsample_bytree=0.8, reg_lambda=1.0,\n    eval_metric='logloss', tree_method='hist', n_jobs=-1, random_state=42,\n    scale_pos_weight=spw  # Menor número de estimadores\n)\n\n# SVM con probabilidad calibrada\nsvm_opt = SVC(\n    kernel='rbf', C=1.0, gamma='scale',\n    class_weight='balanced', probability=True,\n    random_state=42\n)\n\nmodels_opt = [('catb', catb_opt), ('xgb', xgb_opt), ('svm', svm_opt)]\n\n# ===== Voting Classifier =====\nfitted_opt, weights_opt = auc_weights(models_opt, X_train, y_train, X_val, y_val)\nvote_opt = VotingClassifier(estimators=fitted_opt, voting='soft', weights=weights_opt)\n\n# Entrenamiento del Voting Classifier\nvote_opt.fit(X_train, y_train)\nreport(\"Voting CATB+XGB+SVM\", vote_opt, X_val, y_val)\n\n# Seleccionar el mejor modelo\nbest_model = vote_opt  # Si el VotingClassifier tiene buen rendimiento, puedes prescindir del StackingClassifier\nbest_model.fit(X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T19:08:04.633120Z","iopub.execute_input":"2025-11-04T19:08:04.633415Z","iopub.status.idle":"2025-11-04T19:09:26.535689Z","shell.execute_reply.started":"2025-11-04T19:08:04.633394Z","shell.execute_reply":"2025-11-04T19:09:26.534894Z"}},"outputs":[{"name":"stdout","text":"scale_pos_weight=2.32\ncatb: AUC=0.9446\nxgb: AUC=0.9414\nsvm: AUC=0.9443\nPesos: {'catb': 0.334, 'xgb': 0.332, 'svm': 0.334}\n[Voting CATB+XGB+SVM] AUC=0.9486  F1=0.8214  Acc=0.9026\n","output_type":"stream"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"VotingClassifier(estimators=[('catb',\n                              <catboost.core.CatBoostClassifier object at 0x79577a789e90>),\n                             ('xgb',\n                              XGBClassifier(base_score=None, booster=None,\n                                            callbacks=None,\n                                            colsample_bylevel=None,\n                                            colsample_bynode=None,\n                                            colsample_bytree=0.8, device=None,\n                                            early_stopping_rounds=None,\n                                            enable_categorical=False,\n                                            eval_metric='logloss',\n                                            feature_types=None, gamma=None,\n                                            grow_pol...\n                                            max_delta_step=None, max_depth=5,\n                                            max_leaves=None,\n                                            min_child_weight=None, missing=nan,\n                                            monotone_constraints=None,\n                                            multi_strategy=None,\n                                            n_estimators=200, n_jobs=-1,\n                                            num_parallel_tree=None,\n                                            random_state=42, ...)),\n                             ('svm',\n                              SVC(class_weight='balanced', probability=True,\n                                  random_state=42))],\n                 voting='soft',\n                 weights=[0.33418560792180907, 0.33182853601305584,\n                          0.3339858560651351])","text/html":"<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;catb&#x27;,\n                              &lt;catboost.core.CatBoostClassifier object at 0x79577a789e90&gt;),\n                             (&#x27;xgb&#x27;,\n                              XGBClassifier(base_score=None, booster=None,\n                                            callbacks=None,\n                                            colsample_bylevel=None,\n                                            colsample_bynode=None,\n                                            colsample_bytree=0.8, device=None,\n                                            early_stopping_rounds=None,\n                                            enable_categorical=False,\n                                            eval_metric=&#x27;logloss&#x27;,\n                                            feature_types=None, gamma=None,\n                                            grow_pol...\n                                            max_delta_step=None, max_depth=5,\n                                            max_leaves=None,\n                                            min_child_weight=None, missing=nan,\n                                            monotone_constraints=None,\n                                            multi_strategy=None,\n                                            n_estimators=200, n_jobs=-1,\n                                            num_parallel_tree=None,\n                                            random_state=42, ...)),\n                             (&#x27;svm&#x27;,\n                              SVC(class_weight=&#x27;balanced&#x27;, probability=True,\n                                  random_state=42))],\n                 voting=&#x27;soft&#x27;,\n                 weights=[0.33418560792180907, 0.33182853601305584,\n                          0.3339858560651351])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;catb&#x27;,\n                              &lt;catboost.core.CatBoostClassifier object at 0x79577a789e90&gt;),\n                             (&#x27;xgb&#x27;,\n                              XGBClassifier(base_score=None, booster=None,\n                                            callbacks=None,\n                                            colsample_bylevel=None,\n                                            colsample_bynode=None,\n                                            colsample_bytree=0.8, device=None,\n                                            early_stopping_rounds=None,\n                                            enable_categorical=False,\n                                            eval_metric=&#x27;logloss&#x27;,\n                                            feature_types=None, gamma=None,\n                                            grow_pol...\n                                            max_delta_step=None, max_depth=5,\n                                            max_leaves=None,\n                                            min_child_weight=None, missing=nan,\n                                            monotone_constraints=None,\n                                            multi_strategy=None,\n                                            n_estimators=200, n_jobs=-1,\n                                            num_parallel_tree=None,\n                                            random_state=42, ...)),\n                             (&#x27;svm&#x27;,\n                              SVC(class_weight=&#x27;balanced&#x27;, probability=True,\n                                  random_state=42))],\n                 voting=&#x27;soft&#x27;,\n                 weights=[0.33418560792180907, 0.33182853601305584,\n                          0.3339858560651351])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>catb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CatBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;catboost.core.CatBoostClassifier object at 0x79577a789e90&gt;</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>xgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n              feature_types=None, gamma=None, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=0.03, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n              max_leaves=None, min_child_weight=None, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=200,\n              n_jobs=-1, num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>svm</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(class_weight=&#x27;balanced&#x27;, probability=True, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"},"metadata":{}}],"execution_count":24},{"cell_type":"markdown","source":"## 8️⃣ Predicciones Finales en Test","metadata":{}},{"cell_type":"code","source":"\ny_pred_test = best_model.predict(X_test)\ny_pred_proba_test = best_model.predict_proba(X_test)[:, 1]\n\n# Crear submission\nsubmission = pd.DataFrame({\n    'patient_id': df_test_final['patient_id'],\n    'has_diabetes': y_pred_test,\n    'probability': y_pred_proba_test\n})\n\n# En tu notebook - al final\nimport pickle\n\n\npickle.dump(best_model, open('best_model.pkl', 'wb'))\n\nimport pickle\n\nmodel = pickle.load(open('best_model.pkl', 'rb'))\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T19:09:45.512661Z","iopub.execute_input":"2025-11-04T19:09:45.512980Z","iopub.status.idle":"2025-11-04T19:09:45.888837Z","shell.execute_reply.started":"2025-11-04T19:09:45.512957Z","shell.execute_reply":"2025-11-04T19:09:45.888235Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"print(\"\\n\" + \"=\" * 80)\nprint(\"GENERANDO PREDICCIONES EN TEST\")\nprint(\"=\" * 80)\n\nprint(\"\\n Prediciendo...\")\ny_pred_test = best_model.predict(X_test)\ny_pred_proba_test = best_model.predict_proba(X_test)[:, 1]\n\n# Crear submission\nsubmission = pd.DataFrame({\n    'patient_id': df_test_final['patient_id'],\n    'has_diabetes': y_pred_test,\n    'probability': y_pred_proba_test\n})\n\nprint(f\"\\n✅ {len(submission)} predicciones generadas\")\n\nprint(f\"\\n📊 Distribución predicciones:\")\ndist = submission['has_diabetes'].value_counts()\nprint(f\"   Negativo (0): {dist[0]} ({dist[0]/len(submission)*100:.1f}%)\")\nprint(f\"   Positivo (1): {dist[1]} ({dist[1]/len(submission)*100:.1f}%)\")\n\nprint(f\"\\n📊 Probabilidades:\")\nprint(f\"   Media: {submission['probability'].mean():.4f}\")\nprint(f\"   Min: {submission['probability'].min():.4f}\")\nprint(f\"   Max: {submission['probability'].max():.4f}\")\n\nprint(f\"\\n📋 PRIMERAS 10 PREDICCIONES:\")\nprint(submission.head(10).to_string(index=False))\ndef parse_submission(id):\n    id = str(id)\n    length = len(id)\n    return \"patient_\" + \"0\"* (5 - length) + id\n\nsubmission[\"patient_id\"] = submission[\"patient_id\"].apply(parse_submission)\nsubmission[[\"patient_id\",\"has_diabetes\"]].to_csv(\"submission.csv\", index=False)\nprint(f\"\\nGuardado: submission.csv\")\nimport joblib\nscalers = [scaler_age, scaler_bmi, scaler_hba1c, scaler_glucose]\n\njoblib.dump(best_model, \"model.pkl\")\njoblib.dump(scalers, \"scalers.pkl\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T19:03:38.305776Z","iopub.execute_input":"2025-11-04T19:03:38.306480Z","iopub.status.idle":"2025-11-04T19:03:38.765167Z","shell.execute_reply.started":"2025-11-04T19:03:38.306454Z","shell.execute_reply":"2025-11-04T19:03:38.764291Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nGENERANDO PREDICCIONES EN TEST\n================================================================================\n\n Prediciendo...\n\n✅ 300 predicciones generadas\n\n📊 Distribución predicciones:\n   Negativo (0): 218 (72.7%)\n   Positivo (1): 82 (27.3%)\n\n📊 Probabilidades:\n   Media: 0.2887\n   Min: 0.0003\n   Max: 0.9994\n\n📋 PRIMERAS 10 PREDICCIONES:\n patient_id  has_diabetes  probability\n        139             0     0.010946\n        252             0     0.005858\n        259             0     0.009183\n        335             1     0.956264\n        699             0     0.001573\n        977             0     0.033190\n       1025             0     0.092884\n       1145             0     0.028866\n       1217             0     0.443703\n       1235             1     0.858153\n\nGuardado: submission.csv\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"['scalers.pkl']"},"metadata":{}}],"execution_count":23},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}}]}